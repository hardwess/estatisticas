{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idade</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Dor_Peito</th>\n",
       "      <th>PA_rep</th>\n",
       "      <th>Col_Serico</th>\n",
       "      <th>ASJ</th>\n",
       "      <th>ECG_rep</th>\n",
       "      <th>MFC</th>\n",
       "      <th>AINEX</th>\n",
       "      <th>DEPSTEX</th>\n",
       "      <th>INCLI</th>\n",
       "      <th>CA</th>\n",
       "      <th>TAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Idade  Sexo  Dor_Peito  PA_rep  Col_Serico  ASJ  ECG_rep  MFC  AINEX  \\\n",
       "0       63     1          1     145         233    1        2  150      0   \n",
       "1       67     1          4     160         286    0        2  108      1   \n",
       "2       67     1          4     120         229    0        2  129      1   \n",
       "3       37     1          3     130         250    0        0  187      0   \n",
       "4       41     0          2     130         204    0        2  172      0   \n",
       "..     ...   ...        ...     ...         ...  ...      ...  ...    ...   \n",
       "297     57     0          4     140         241    0        0  123      1   \n",
       "298     45     1          1     110         264    0        0  132      0   \n",
       "299     68     1          4     144         193    1        0  141      0   \n",
       "300     57     1          4     130         131    0        0  115      1   \n",
       "301     57     0          2     130         236    0        2  174      0   \n",
       "\n",
       "     DEPSTEX  INCLI   CA  TAL  \n",
       "0        2.3      3  0.0  6.0  \n",
       "1        1.5      2  3.0  3.0  \n",
       "2        2.6      2  2.0  7.0  \n",
       "3        3.5      3  0.0  3.0  \n",
       "4        1.4      1  0.0  3.0  \n",
       "..       ...    ...  ...  ...  \n",
       "297      0.2      2  0.0  7.0  \n",
       "298      1.2      2  0.0  7.0  \n",
       "299      3.4      2  2.0  7.0  \n",
       "300      1.2      2  1.0  7.0  \n",
       "301      0.0      2  1.0  3.0  \n",
       "\n",
       "[297 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar o dataset\n",
    "raw_dataset = fetch_ucirepo(id=45)\n",
    "\n",
    "# Extrair os valores dos dados corretamente\n",
    "data_values = raw_dataset.data['features']\n",
    "target_values = raw_dataset.data['targets']\n",
    "\n",
    "# Criar um DataFrame com os dados principais\n",
    "dataset = pd.DataFrame(data_values)\n",
    "\n",
    "# Buscar o dataset\n",
    "raw_dataset = fetch_ucirepo(id=45)\n",
    "\n",
    "# Extrair os valores dos dados corretamente\n",
    "data_values = raw_dataset.data['features']\n",
    "target_values = raw_dataset.data['targets']\n",
    "\n",
    "# Criar um DataFrame com os dados principais\n",
    "dataset = pd.DataFrame(data_values)\n",
    "\n",
    "# Adicionar a coluna 'NUM' ao DataFrame principal\n",
    "dataset['NUM'] = target_values\n",
    "\n",
    "# Nomes que serão dados as colunas na mesma ordem em que aparecem\n",
    "heart_disease_cols = [ 'Idade',\n",
    " 'Sexo',\n",
    " 'Dor_Peito',\n",
    " 'PA_rep',\n",
    " 'Col_Serico', \n",
    " 'ASJ',\n",
    " 'ECG_rep',\n",
    " 'MFC',\n",
    " 'AINEX',\n",
    " 'DEPSTEX',\n",
    " 'INCLI',\n",
    " 'CA',\n",
    " 'TAL',\n",
    " 'NUM']\n",
    "\n",
    "# Renomear as colunas do DataFrame\n",
    "dataset.columns = heart_disease_cols\n",
    "\n",
    "dataset['NUM'] = dataset['NUM'].replace({2: 1})\n",
    "dataset['NUM'] = dataset['NUM'].replace({3: 1})\n",
    "dataset['NUM'] = dataset['NUM'].replace({4: 1})\n",
    "\n",
    "# Realizar os tratamentos necessários no dataset\n",
    "# Exemplo de tratamento (ajuste conforme necessário)\n",
    "dataset.dropna(inplace=True)  # Remover valores nulos\n",
    "# dataset = dataset[dataset['some_column'] > 0]  # Filtrar linhas com base em uma condição\n",
    "\n",
    "target_values = dataset['NUM'].copy()\n",
    "\n",
    "# Separar as features e o target\n",
    "X = dataset.drop('NUM', axis=1).copy()\n",
    "y = target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\estatisticas\\estatistiaEnv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5339 - loss: 0.7150 - val_accuracy: 0.8833 - val_loss: 0.4723\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8363 - loss: 0.4559 - val_accuracy: 0.8500 - val_loss: 0.3557\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8752 - loss: 0.3647 - val_accuracy: 0.8833 - val_loss: 0.3201\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.3756 - val_accuracy: 0.8833 - val_loss: 0.3034\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.2969 - val_accuracy: 0.9000 - val_loss: 0.3008\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8484 - loss: 0.2936 - val_accuracy: 0.9000 - val_loss: 0.2946\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8556 - loss: 0.3073 - val_accuracy: 0.9000 - val_loss: 0.2941\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.2885 - val_accuracy: 0.9000 - val_loss: 0.2938\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.3019 - val_accuracy: 0.8833 - val_loss: 0.2947\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9130 - loss: 0.2512 - val_accuracy: 0.8667 - val_loss: 0.3011\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.2922 - val_accuracy: 0.8667 - val_loss: 0.2940\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9315 - loss: 0.2429 - val_accuracy: 0.8833 - val_loss: 0.2985\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2462 - val_accuracy: 0.8667 - val_loss: 0.2968\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2072 - val_accuracy: 0.8667 - val_loss: 0.3039\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9026 - loss: 0.2449 - val_accuracy: 0.8667 - val_loss: 0.3076\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2029 - val_accuracy: 0.8667 - val_loss: 0.3030\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.1990 - val_accuracy: 0.8833 - val_loss: 0.3135\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.1796 - val_accuracy: 0.8833 - val_loss: 0.3140\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.1713 - val_accuracy: 0.8667 - val_loss: 0.3257\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9580 - loss: 0.1785 - val_accuracy: 0.9000 - val_loss: 0.3190\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9760 - loss: 0.1481 - val_accuracy: 0.8667 - val_loss: 0.3352\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.1280 - val_accuracy: 0.8833 - val_loss: 0.3380\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.1406 - val_accuracy: 0.8833 - val_loss: 0.3372\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9752 - loss: 0.1380 - val_accuracy: 0.9000 - val_loss: 0.3381\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.1108 - val_accuracy: 0.9000 - val_loss: 0.3383\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1275 - val_accuracy: 0.9167 - val_loss: 0.3453\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.1122 - val_accuracy: 0.8667 - val_loss: 0.3518\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.1011 - val_accuracy: 0.9167 - val_loss: 0.3557\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0812 - val_accuracy: 0.9167 - val_loss: 0.3672\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0792 - val_accuracy: 0.9000 - val_loss: 0.3671\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0778 - val_accuracy: 0.9167 - val_loss: 0.3705\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 0.0771 - val_accuracy: 0.9167 - val_loss: 0.3738\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0808 - val_accuracy: 0.9167 - val_loss: 0.3842\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0502 - val_accuracy: 0.8833 - val_loss: 0.3996\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0654 - val_accuracy: 0.9167 - val_loss: 0.3987\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0480 - val_accuracy: 0.9000 - val_loss: 0.4107\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0567 - val_accuracy: 0.9167 - val_loss: 0.4158\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0553 - val_accuracy: 0.9000 - val_loss: 0.4235\n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0427 - val_accuracy: 0.8833 - val_loss: 0.4436\n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0489 - val_accuracy: 0.9000 - val_loss: 0.4381\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0545 - val_accuracy: 0.9167 - val_loss: 0.4410\n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0328 - val_accuracy: 0.9000 - val_loss: 0.4574\n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0441 - val_accuracy: 0.9167 - val_loss: 0.4547\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0370 - val_accuracy: 0.9167 - val_loss: 0.4676\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0352 - val_accuracy: 0.8833 - val_loss: 0.4709\n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0308 - val_accuracy: 0.9167 - val_loss: 0.4756\n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0309 - val_accuracy: 0.9167 - val_loss: 0.4874\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0272 - val_accuracy: 0.9000 - val_loss: 0.5018\n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0253 - val_accuracy: 0.9167 - val_loss: 0.5003\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0220 - val_accuracy: 0.9167 - val_loss: 0.5091\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9132 - loss: 0.4553 \n",
      "Model Loss: 0.5091359615325928\n",
      "Model Accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "# Dividir o dataset em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir o modelo da rede neural\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' para classificação multiclasse\n",
    "\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Use 'categorical_crossentropy' para classificação multiclasse\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, validation_data=(X_test, y_test))  # Aumentar o número de épocas\n",
    "\n",
    "# Avaliar o modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Loss: {loss}')\n",
    "print(f'Model Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estatistiaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
